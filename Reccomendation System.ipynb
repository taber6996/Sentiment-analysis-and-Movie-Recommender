{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4634b8d1",
   "metadata": {},
   "source": [
    "# Sentiment analysis from Twitter and Content Filtering Reccomendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61b9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cccbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a82c0",
   "metadata": {},
   "source": [
    "## Sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c6857",
   "metadata": {},
   "source": [
    "For this part we are going to use TextBlob, since using a pretrained sentiment analizer is way more convinient and it also provides good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8656d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba66211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\taber\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\taber\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\taber\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\taber\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\taber\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\taber\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ceb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_tweet_sentiment(tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(tweet)\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c69fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions\n",
    "\n",
    "def get_movie_from_tweet(tweet):\n",
    "    \"\"\"Utility funcion to get the title of a film from a tweet,\n",
    "    the title needs to be between quotations for the function to work\"\"\"\n",
    "    return re.findall('\"([^\"]*)\"', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3a6765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sompoy']\n"
     ]
    }
   ],
   "source": [
    "s = 'I really liked \"sompoy\"'\n",
    "print(get_movie_from_tweet(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ca708d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "s = 'Dune was so dope'\n",
    "print(get_tweet_sentiment(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7c79b",
   "metadata": {},
   "source": [
    "## Reccomendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208e08f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8dc0f",
   "metadata": {},
   "source": [
    "This reccomendation system uses an item-based approach. Items usually don’t change much, and item based approach often can be computed offline and served without constantly re-training. Whereas User-based approach is way more mutable and dynamic due to the nature of users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c29a2",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f8489",
   "metadata": {},
   "source": [
    "The dataset selected is MovieTweetings (https://github.com/sidooms/MovieTweetings), MovieTweetings is a dataset consisting of ratings on movies that were contained in well-structured tweets on Twitter. I used this dataset because it was more convinient than rescuing well-structured tweets from the Twitter dataframe, mainly because users don't usually follow a common blueprint to write their opinions about movies (like using some type of quotation for the movie title). For the record, any dataset with movies could be used but due to the sheer simplicity of this dataset made it the most suitable for this paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0c4b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taber\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "colnames = ['movie_id', 'movie_title', 'genre'] \n",
    "movies_df = pd.read_csv('MovieTweetings-master/latest/movies.dat', header=0,encoding='utf-8',names=colnames,sep='::', dtype={\n",
    "    'movie_id':int,\n",
    "    'movie_title':str,\n",
    "    'genre':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c251fe3",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af3aa0",
   "metadata": {},
   "source": [
    "In the following cells we apply some basic operations to get rid on NaN values, change the type from columns from Object to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98c8221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['movie_title'] = movies_df['movie_title'].astype('string')\n",
    "movies_df['genre'] = movies_df['genre'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "162a0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd51f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>La sortie des usines Lumière (1895)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>The Arrival of a Train (1896)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>The Oxford and Cambridge University Boat Race ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>Le manoir du diable (1896)</td>\n",
       "      <td>Short|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>Une nuit terrible (1896)</td>\n",
       "      <td>Short|Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38012</th>\n",
       "      <td>15711402</td>\n",
       "      <td>Les rois de l&amp;x27;arnaque (2021)</td>\n",
       "      <td>Crime|Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>15831978</td>\n",
       "      <td>Cash (2021)</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38014</th>\n",
       "      <td>15839820</td>\n",
       "      <td>Sompoy (2021)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15842076</td>\n",
       "      <td>The Making of &amp;x27;Rocky vs. Drago&amp;x27; (2021)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38016</th>\n",
       "      <td>16058736</td>\n",
       "      <td>Rocky IV: Rocky vs Drago - The Ultimate Direct...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38017 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id                                        movie_title  \\\n",
       "0            10                La sortie des usines Lumière (1895)   \n",
       "1            12                      The Arrival of a Train (1896)   \n",
       "2            25  The Oxford and Cambridge University Boat Race ...   \n",
       "3            91                         Le manoir du diable (1896)   \n",
       "4           131                           Une nuit terrible (1896)   \n",
       "...         ...                                                ...   \n",
       "38012  15711402                   Les rois de l&x27;arnaque (2021)   \n",
       "38013  15831978                                        Cash (2021)   \n",
       "38014  15839820                                      Sompoy (2021)   \n",
       "38015  15842076     The Making of &x27;Rocky vs. Drago&x27; (2021)   \n",
       "38016  16058736  Rocky IV: Rocky vs Drago - The Ultimate Direct...   \n",
       "\n",
       "                     genre  \n",
       "0        Documentary|Short  \n",
       "1        Documentary|Short  \n",
       "2                  unknown  \n",
       "3             Short|Horror  \n",
       "4      Short|Comedy|Horror  \n",
       "...                    ...  \n",
       "38012    Crime|Documentary  \n",
       "38013              unknown  \n",
       "38014       Comedy|Romance  \n",
       "38015          Documentary  \n",
       "38016              unknown  \n",
       "\n",
       "[38017 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d6ecf",
   "metadata": {},
   "source": [
    "It is also needed to change a bit the format of the genre column and movie_title column, getting rid of weird characters to have an easier time working with it. We use NLTK to process the text, specifically we use lemmatization. Lemmatization is the process of converting a word to its base form considering the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7595cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "\n",
    "lemmatizer = wordnet.WordNetLemmatizer()\n",
    "genres = movies_df[\"genre\"]\n",
    "li=[]\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    temp = genres[i].lower()\n",
    "    temp = temp.split(\"|\")\n",
    "    temp = [lemmatizer.lemmatize(word) for word in temp]\n",
    "    li.append(\" \".join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "139d2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = movies_df[\"movie_title\"]\n",
    "lj=[]\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    temp = titles[i].split(\"(\")\n",
    "    temp = temp[0].lower()\n",
    "    lj.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a62ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['movie_title'] = lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6136d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genre'] = li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e46fa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['movie_title'] = movies_df['movie_title'].astype('string')\n",
    "movies_df['genre'] = movies_df['genre'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11b0f4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id        int32\n",
       "movie_title    string\n",
       "genre          string\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015a5ad",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bb956",
   "metadata": {},
   "source": [
    "The first step is to tokenize the genre column, thus creating a vector for each movie in which we represent the corresponding genre the movie is catalogued. For this purpose we use CountVectorizer, it takes a collection of text documents and converts it to a matrix of token counts, since we didnt use an a-priori dictionary nor an analyzer that does some kind of feature selection,\n",
    "the number of features will be equal to the vocabulary size found by analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c7dd6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding based on similar movies\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(movies_df[\"genre\"]).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00dab9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vector : \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "\n",
      "Note: First row of above count vector:  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Columns Coresponding to above count vector is :\n",
      " ['action', 'adult', 'adventure', 'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy', 'fi', 'film', 'game', 'history', 'horror', 'music', 'musical', 'mystery', 'news', 'noir', 'reality', 'romance', 'sci', 'short', 'show', 'sport', 'talk', 'thriller', 'tv', 'unknown', 'war', 'western']\n"
     ]
    }
   ],
   "source": [
    "print(\"Count Vector : \\n\",X)\n",
    "print(\"\\nNote: First row of above count vector: \",X[0])\n",
    "print(\"\\nColumns Coresponding to above count vector is :\\n\",cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2812c550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>la sortie des usines lumière</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>the arrival of a train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>the oxford and cambridge university boat race</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>le manoir du diable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>une nuit terrible</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38012</th>\n",
       "      <td>15711402</td>\n",
       "      <td>les rois de l&amp;x27;arnaque</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>15831978</td>\n",
       "      <td>cash</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38014</th>\n",
       "      <td>15839820</td>\n",
       "      <td>sompoy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15842076</td>\n",
       "      <td>the making of &amp;x27;rocky vs. drago&amp;x27;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38016</th>\n",
       "      <td>16058736</td>\n",
       "      <td>rocky iv: rocky vs drago - the ultimate direct...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38017 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id                                        movie_title  0  1  2  \\\n",
       "0            10                      la sortie des usines lumière   0  0  0   \n",
       "1            12                            the arrival of a train   0  0  0   \n",
       "2            25     the oxford and cambridge university boat race   0  0  0   \n",
       "3            91                               le manoir du diable   0  0  0   \n",
       "4           131                                 une nuit terrible   0  0  0   \n",
       "...         ...                                                ... .. .. ..   \n",
       "38012  15711402                         les rois de l&x27;arnaque   0  0  0   \n",
       "38013  15831978                                              cash   0  0  0   \n",
       "38014  15839820                                            sompoy   0  0  0   \n",
       "38015  15842076           the making of &x27;rocky vs. drago&x27;   0  0  0   \n",
       "38016  16058736  rocky iv: rocky vs drago - the ultimate direct...  0  0  0   \n",
       "\n",
       "       3  4  5  6  7  ...  23  24  25  26  27  28  29  30  31  32  \n",
       "0      0  0  0  0  1  ...   0   1   0   0   0   0   0   0   0   0  \n",
       "1      0  0  0  0  1  ...   0   1   0   0   0   0   0   0   0   0  \n",
       "2      0  0  0  0  0  ...   0   0   0   0   0   0   0   1   0   0  \n",
       "3      0  0  0  0  0  ...   0   1   0   0   0   0   0   0   0   0  \n",
       "4      0  0  1  0  0  ...   0   1   0   0   0   0   0   0   0   0  \n",
       "...   .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "38012  0  0  0  1  1  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "38013  0  0  0  0  0  ...   0   0   0   0   0   0   0   1   0   0  \n",
       "38014  0  0  1  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "38015  0  0  0  0  1  ...   0   0   0   0   0   0   0   0   0   0  \n",
       "38016  0  0  0  0  0  ...   0   0   0   0   0   0   0   1   0   0  \n",
       "\n",
       "[38017 rows x 35 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = movies_df.loc[:,['movie_id','movie_title']]\n",
    "output = output.join(pd.DataFrame(X))\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9cf38",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69dd52",
   "metadata": {},
   "source": [
    "Cosine similarity is a measure of similarity between two sequences of numbers. For defining it, the sequences are viewed as vectors in an inner product space, and the cosine similarity is defined as the cosine of the angle between them, that is, the dot product of the vectors divided by the product of their lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7a12606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Row corresponds to a movie name\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = cosine_similarity(X) \n",
    "#Each row of matrix coressponds to similarity of a movie with all other movies (row len = 10329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8305bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         ... 0.         0.70710678 0.        ]\n",
      " [1.         1.         0.         ... 0.         0.70710678 0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.70710678 0.70710678 0.         ... 0.         1.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a0a1f",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c85333f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('sompoy ' in output['movie_title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ef898bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cash \n"
     ]
    }
   ],
   "source": [
    "print(get_movie_by_id(15831978))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7a56f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_movie_df(movie):\n",
    "    return movie in output['movie_title'].values\n",
    "def get_movie_id(movie):\n",
    "    return output.loc[output['movie_title'] == movie].movie_id\n",
    "def get_movie_index(movie):\n",
    "    return output.loc[output['movie_title'] == movie].index\n",
    "def get_movie_by_index(idx):\n",
    "    return output.movie_title[idx]\n",
    "def get_movie_by_id(mv_id):\n",
    "    return output.loc[output['movie_id']==mv_id,['movie_title']].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aa5ee764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write an opinion about a movie: i liked \"sompoy\"\n",
      "Since u watched ---> sompoy  <--- We recommend you\n",
      "101 reykjavík \n",
      "loser \n",
      "miss partners \n",
      "celal ile ceren \n",
      "let my people go! \n",
      "reinas \n",
      "just friends \n",
      "buying the cow \n",
      "keinohrhasen \n",
      "the kissing booth 2 \n",
      "the food guide to love \n",
      "she remembers, he forgets \n",
      "chacun cherche son chat \n",
      "we were dancing \n",
      "left right and centre \n"
     ]
    }
   ],
   "source": [
    "tweet = input(\"Write an opinion about a movie: \")\n",
    "movie_title = get_movie_from_tweet(tweet)[0].lower() + \" \"\n",
    "if check_movie_df(movie_title):\n",
    "    sentiment = get_tweet_sentiment(tweet)\n",
    "    if sentiment == 'positive':\n",
    "        movie_index = get_movie_index(movie_title)\n",
    "        movie_id = get_movie_id(movie_title)\n",
    "        similarity_values = pd.Series(similarities[movie_index][0])\n",
    "        similarity_values.sort_values(ascending=False)\n",
    "        similar_movie_indexes = list(similarity_values.sort_values(ascending=False).index)\n",
    "        similar_movie_indexes.remove(movie_index)\n",
    "        \n",
    "        print(\"Since u watched --->\",get_movie_by_id(movie_id.values[0]),\"<--- We recommend you\")\n",
    "        for i in range(15):\n",
    "            print(get_movie_by_index(similar_movie_indexes[i]))\n",
    "    else:\n",
    "        print(\"No te recomendaré peliculas parecidas\")\n",
    "else:\n",
    "    print(\"La película no esta en el sistema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89674b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
